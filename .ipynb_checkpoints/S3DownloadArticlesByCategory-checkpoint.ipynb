{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototype code to scrape the top headlines and their corresponding article text from News API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T17:03:57.120435Z",
     "start_time": "2020-07-12T17:03:56.468435Z"
    }
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import json\n",
    "import boto3 \n",
    "import os\n",
    "from io import StringIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T17:03:57.213430Z",
     "start_time": "2020-07-12T17:03:57.123435Z"
    }
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T17:03:57.228430Z",
     "start_time": "2020-07-12T17:03:57.215432Z"
    }
   },
   "outputs": [],
   "source": [
    "# API Key for News API\n",
    "secret = 'd05c3ae08abd461f90b3dc555af1bb59'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T17:03:57.244431Z",
     "start_time": "2020-07-12T17:03:57.230431Z"
    }
   },
   "outputs": [],
   "source": [
    "# s3 secret\n",
    "ACCESS_KEY = \"<KEY>\" \n",
    "SECRET_KEY = \"<SECRET>\" \n",
    "BUCKET_NAME ='<bucket>'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T17:03:57.493430Z",
     "start_time": "2020-07-12T17:03:57.246430Z"
    }
   },
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\n",
    "    's3',\n",
    "    region_name='us-east-1',\n",
    "    aws_access_key_id=ACCESS_KEY,\n",
    "    aws_secret_access_key=SECRET_KEY\n",
    ").Bucket(BUCKET_NAME)\n",
    "\n",
    "json.load_s3 = lambda f: json.load(s3.Object(key=f).get()[\"Body\"])\n",
    "json.dump_s3 = lambda obj, f: s3.Object(key=f).put(Body=json.dumps(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T17:03:57.508433Z",
     "start_time": "2020-07-12T17:03:57.495431Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the endpoint to extract all the top headlines \n",
    "url = 'https://newsapi.org/v2/top-headlines?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T17:03:57.524431Z",
     "start_time": "2020-07-12T17:03:57.510430Z"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the query and number of returns - Limit the headlines to country US, for now\n",
    "parameters = {\n",
    "    'language': 'en',\n",
    "    'country':'us',\n",
    "    'pageSize': 100,\n",
    "    'apiKey': secret \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T17:03:57.539435Z",
     "start_time": "2020-07-12T17:03:57.527437Z"
    }
   },
   "outputs": [],
   "source": [
    "categories = ['business','entertainment','general','health','science','sports','technology']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T17:03:58.226435Z",
     "start_time": "2020-07-12T17:03:57.541431Z"
    }
   },
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "from newspaper import Config\n",
    "\n",
    "\n",
    "article_title = []\n",
    "article_authors = []\n",
    "article_text = []\n",
    "article_summary = []\n",
    "article_date = []\n",
    "article_top_image = []\n",
    "failed_url = []\n",
    "category_articles ={}\n",
    "pages= range(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T17:03:58.242436Z",
     "start_time": "2020-07-12T17:03:58.228435Z"
    }
   },
   "outputs": [],
   "source": [
    "#category_dataframe = pd.read_json(f'resources/business_top_headline_data.json').T\n",
    "#category_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T17:06:23.501434Z",
     "start_time": "2020-07-12T17:03:58.245434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9Q29rWjA2amFST1XSAQA?oc=5\n",
      "***FAILED TO DOWNLOAD***https://news.google.com/__i/rss/rd/articles/CBMiXmh0dHBzOi8vd3d3LmFnd2ViLmNvbS9hcnRpY2xlL2Nvcm4tbWFya2V0LXVucGhhc2VkLXByb2R1Y3Rpb24tZHJvcC1sYXJnZS1jaGluZXNlLWJ1eS1oZXJlcy13aHnSAQA?oc=5\n",
      "Using DataFrame (310, 10) Adding 22\n",
      "(332, 10)\n",
      "entertainment\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9NnhhVW96aHItU03SAQA?oc=5\n",
      "Unable to parse article: http://komonews.com/news/local/seattles-lady-a-to-lady-antebellum-we-cant-both-be-lady-a-youll-bury-me\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9dWZkcDJJNU9mUzjSAQA?oc=5\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9MW1tRW55RWFIM03SAQA?oc=5\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9MUVVeUV3b0xEVjTSAQA?oc=5\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9d0FCcndlVE5xRknSAQA?oc=5\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9MWszeTRWZFBURnPSAQA?oc=5\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9Y2gtcXRzbzhtQUnSAQA?oc=5\n",
      "Using DataFrame (290, 10) Adding 15\n",
      "(305, 10)\n",
      "general\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9amhfSkNsc0xwdDTSAQA?oc=5\n",
      "Number of articles: 50\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9ZUpaaVJxWTdwV03SAQA?oc=5\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9UzJBNnBZcnVHM2fSAQA?oc=5\n",
      "***FAILED TO DOWNLOAD***https://www.washingtonpost.com/nation/2020/07/10/coronavirus-obituary-blames-arizona-ducey/\n",
      "Using DataFrame (268, 10) Adding 22\n",
      "(290, 10)\n",
      "health\n",
      "Unable to parse article: http://news4sanantonio.com/news/local/feeding-tubes-hallucinations-and-numb-toes-one-texans-battle-to-survive-covid-19\n",
      "Unable to parse article: https://www.goodmorningamerica.com/shop/story/brighten-smile-electric-toothbrush-now-3999-71717081\n",
      "***FAILED TO DOWNLOAD***https://news.google.com/__i/rss/rd/articles/CBMiRGh0dHBzOi8vd3d3LnNhbmx1aXNvYmlzcG8uY29tL25ld3MvY29yb25hdmlydXMvYXJ0aWNsZTI0NDE3MDg5Mi5odG1s0gFEaHR0cHM6Ly9hbXAuc2FubHVpc29iaXNwby5jb20vbmV3cy9jb3JvbmF2aXJ1cy9hcnRpY2xlMjQ0MTcwODkyLmh0bWw?oc=5\n",
      "Unable to parse article: http://komonews.com/news/coronavirus/health-officials-say-we-must-still-work-to-contain-spread-of-coronavirus\n",
      "Unable to parse article: http://wcyb.com/news/local/tdh-83-new-covid-19-cases-reported-in-northeast-tennessee\n",
      "Unable to parse article: http://news4sanantonio.com/news/local/i-thought-this-was-a-hoax-patient-in-their-30s-dies-after-attending-covid-party\n",
      "Unable to parse article: http://upnorthlive.com/news/local/torch-lake-sandbar-listed-as-possible-covid-19-exposure-site-following-4th-of-july-party\n",
      "Using DataFrame (345, 10) Adding 17\n",
      "(362, 10)\n",
      "science\n",
      "Unable to parse article: https://www.nasa.gov/press-release/aviation-scholars-to-speak-with-nasa-astronauts-aboard-space-station/\n",
      "Using DataFrame (173, 10) Adding 7\n",
      "(180, 10)\n",
      "sports\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9NzBDM3NiQWRWdlnSAQA?oc=5\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9bUM4bVNoc214SHfSAQA?oc=5\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9T3ZfUmNXOEdSRFXSAQA?oc=5\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9ZUpaaVJxWTdwV03SAQA?oc=5\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9SzF6S1B3NVltNlnSAQA?oc=5\n",
      "Number of articles: 100\n",
      "***FAILED TO DOWNLOAD***https://nascar.nbcsports.com/2020/07/11/kurt-busch-kyle-busch-kevin-harvick-nascar-kentucky-start-time-lineup/\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9dloyNGN5ZzI1UkXSAQA?oc=5\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9T1hETDN4aFBnbTTSAQA?oc=5\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9UFA4cXQyeDJZNkXSAQA?oc=5\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9b3BPeEdBbndWbm_SAQA?oc=5\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9NlBaN2Q3ODNuZ0nSAQA?oc=5\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9b2ppZ0dtaUpYVjjSAQA?oc=5\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9YjFjQnFrQjEwbTTSAQA?oc=5\n",
      "Using DataFrame (353, 10) Adding 20\n",
      "(373, 10)\n",
      "technology\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9SHJ0dnphb0FnXzTSAQA?oc=5\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9R3pxSXpCbjVXTEHSAQA?oc=5\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9RFpiaDNobHdUUkXSAQA?oc=5\n",
      "Unable to parse article: https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9TGVPa0FFRm1QZXfSAQA?oc=5\n",
      "Unable to parse article: https://www.mmorpg.com/notice/ss-captcha\n",
      "Using DataFrame (300, 10) Adding 14\n",
      "(314, 10)\n",
      "Total number of articles: 117\n"
     ]
    }
   ],
   "source": [
    "count =0\n",
    "for category in categories:\n",
    "    name = category\n",
    "    print(name)\n",
    "    fileName= f'resources/{category}_top_headline_data_new.json'\n",
    "    json_buffer=json.load_s3('Project3/'+fileName)\n",
    "    category_dataframe = pd.read_json(json_buffer).T    \n",
    "    parameters['category'] = category\n",
    "    response = requests.get(url, params=parameters)\n",
    "    if response.status_code != requests.codes.ok:\n",
    "        print(f\"Bad result : {response.url}\")\n",
    "        continue\n",
    "    response_json = response.json()\n",
    "\n",
    "    df = pd.DataFrame.from_dict(response_json)\n",
    "    df = pd.concat([df.drop(['articles'], axis=1), df['articles'].apply(pd.Series)], axis=1) \n",
    "\n",
    "    rows = []\n",
    "    for index, row in df.iterrows():\n",
    "        h = row['url']\n",
    "        # skip record if we already downloaded article\n",
    "        if h in category_dataframe['url'].values:\n",
    "            continue \n",
    "        user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'\n",
    "        config = Config()\n",
    "        config.verbose=True\n",
    "        config.browser_user_agent = user_agent\n",
    "        newsarticle = Article(h, config=config)\n",
    "        try :\n",
    "            newsarticle.download()\n",
    "            newsarticle.parse()\n",
    "            if not newsarticle.text :\n",
    "                print(f\"Unable to parse article: {h}\")\n",
    "                continue \n",
    "            artdict = {}                \n",
    "            artdict['articleText']=newsarticle.text\n",
    "            artdict['articleSummary']=''   # Place Holder for bert summary\n",
    "            artdict['articleSentiment']='' # Place Holder for calculated Sentiment Analysis\n",
    "            for column in df:\n",
    "                #print(column)\n",
    "                if column in ['status', 'totalResults','content'] :\n",
    "                    continue \n",
    "                artdict[column]= row[column]\n",
    "            rows.append(artdict)\n",
    "            count += 1\n",
    "            if (count % 50 == 0 ):\n",
    "                print('Number of articles: '+str(count))\n",
    "\n",
    "        except :\n",
    "             print(f'***FAILED TO DOWNLOAD***{newsarticle.url}')\n",
    "             pass\n",
    "\n",
    "    print(f\"Using DataFrame {category_dataframe.shape} Adding {len(rows)}\" )\n",
    "    if len(rows) > 0 :\n",
    "        category_dataframe = category_dataframe.append(pd.DataFrame(rows),ignore_index=True).drop_duplicates(subset='url')\n",
    "        \n",
    "#         df.to_json(f'resources/{category}_top_headline_data_new.json', orient='index')\n",
    "#         category_articles[name] = category_dataframe\n",
    "    print(category_dataframe.shape)\n",
    "    json_buffer = StringIO()\n",
    "    category_dataframe.to_json(json_buffer, orient='index')\n",
    "    json.dump_s3(json_buffer.getvalue(),'Project3/'+fileName)\n",
    "\n",
    "\n",
    "\n",
    "print('Total number of articles: '+str(count))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
